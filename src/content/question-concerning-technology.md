# The question concerning technology in 2023
 
**1.**

In June, we published the text *Anti-Yudkowsky* as an e-book, the print edition of which will be released in November. Having written this text in a month-long burst of writing at the height of AI fervor, we have since in the cooldown period had to take a step back and re-evaluate some of the goals of the text, as well as the goals of further projects which will result from the lines of thought explored therein.

*Who were we writing this text for?* In some ways this is unclear. Perhaps we were writing this text out of frustration for a lack of an audience we felt served us — perhaps we were hoping to make noise loudly enough to assemble one. If the theorist Eliezer Yudkowsky seems arbitrarily singled out against all others, it is because he so specifically is not a mere maker of policy recommendations or futuristic predictions, but rather the father of a sweeping milieu of ways of thinking about all areas of life that is highly distinctive with its jargon and social rituals. But it goes beyond this, because Yudkowsky’s insular subculture of Rationalism is only an extreme version of what we experience in a diffusive form nearly everywhere the most pressing issues around technology are discussed. Yudkowsky is exemplary to us for being acutely “tech-brained”.

So far it has mostly been easier for us to present our thesis on AI to people who are not in the field of software, directly involved with AI, or heavily immersed in AI discourse. They tend to understand what we are saying easily, and are often sympathetic. 

When talking to fellow technologists, on the other hand, often extreme barriers to communication present themselves immediately. An hour can be spent on negotiating epistemological grounds — for instance, an immediate barrier with people sympathetic to Alignment is that they will ask us immediately to give numerical probabilities of likelihood for various scenarios, and we have to defend the decision not to do this. Or often we find ourselves having to articulate something like the value of art or philosophy in the abstract, or explain concepts like faith and the sacred.

In the introduction to *Anti-Yudkowsky*, we write that a simple way to voice our opposition to AI Alignment is to point out the strange quirk of language that leads Bay Area tech types to declare their intention to “solve” fundamental problems of existence — “a startup that solves romance”, “a startup that solves education”, etc. This is just one example of the “tech-brain” at work. We are speaking very loosely at the moment, and there is the danger of falling into the form of empty mockery which passes as critique when one hears certain perspectives on AI dismissed as coming exclusively from "nerds" or “techbros” or what have you. But the tech-brain is not “mere” subcultural affect — it is something that carries immense implications as a framing structure for all discourses around technology. 

Our attempt in *Anti-Yudkowsky* was to unwind the tech-brain in about three hundred pages of writing, as this was evidently too large of a task to accomplish as a mere preamble individual conversations. But the framing of *Anti-Yudkowsky* has perhaps suffered by being entirely posed in the negative. Though it was initially necessary to write in the negative, to clear away as much conceptual clutter as possible, it is time to strive past this, towards fully occupying a position which is rightfully ours. 

Unfortunately, a fully fleshed-out positive thesis on AI specifically will not be possible until after more research-and-development is done. But what we can immediately begin on is attempting this positive task of conceptual reframing — if the grounds for a real, meaningful conversation on artificial intelligence are almost nowhere to be found yet, perhaps we should venture towards answering the question of how we will lay them.

**2.**

Though there is this sense that today’s twenty-four hour “discourse” forces one to confront all sorts of weighty, difficult, anxiety-provoking topics constantly — in another sense, this chatter only serves as a diversion from a deeper set of anxieties that cannot be expressed. As a rule, it seems like amongst the nonstop back-and-forth around relatively paltry political subjects like immigration or taxation, the actual questions worth asking regarding man’s place in the world and the future of civilization do not get spoken of, which is perhaps as desired.

The writing project Angelicism, for all its numerous flaws, was a rare example of an endeavor which did not shy away from confronting the apocalyptic and unthinkable nature of our times in an original manner. The question asked was: how is it possible to make art, or pursue beauty and joy at all, under the assumption of imminent human extinction? (The particular extinction scenario in mind seems to be climate change.) Some kind of answer was perhaps discovered in the latent structure of the internet, and the idea that we are able to discover the divine through its infinite set of potential new semiotic connections. Through this, we are able to make peace with the idea that nothing we make or do today will be borne witness to or remembered, now that the curtains are soon to close.

We live in a civilization of the walking dead, not long for this world. One is free to choose the imminent apocalypse which suits herself best as the anchor for her anxiety. For the tech crowd, we have the potential apocalypse of an unaligned AI as the most narratively satisfying climax to our hubristic endeavors. For Wikipedia-binging military strategy enthusiasts, there are all sorts of paths to nuclear annihilation or towards the collapse of most supply chains one can trace out excitedly and nervously. The most mainstream-friendly apocalypse scenario at this point is of course the climate catastrophe. If you ask around, many regular people in the cities somehow believe through some kind of narrative distortion that they themselves have only ten or fifteen more years to live before climate change renders the globe uninhabitable and merely die. And yet they usually do not seem to be experiencing life like condemned prisoners, only declining to have children — they go to work, watch TV, consume content on social media, go out to bars and restaurants, experiencing all kinds of minor joys and anxieties — and therefore it goes unnoticed that their existential backgrounding is completely unlike that which we expect to be historically normal. They are like everyone else in every external sense, they just have already concluded that the game of living is lost.

But even the narrative of imminent extinction, however, as anxiety-provoking as it seems, is a flight from a greater anxiety — that of having to confront one’s own relationship to the times, and the prospect of one’s duty towards them. *It will all be over soon and then none of this will have mattered, finally, an infinite sleep*. Of course, even the most pessimistic projections for climate change do not predict that it will kill all humans within our lifetime, which suggests the question of why people choose to believe that it will. Is it easier to imagine being blown out like a candle than it is struggling to navigate and fight for the survival of one’s family within a world of declining expectations increasingly torn apart by disasters downstream of the global temperature rise? And could there be a similar dynamic at play for why technologists debate the AI extinction scenario all day as the primary means of describing this technology, preferring the black-and-white outcome to those more delicate to imagine?

What is agreed across the board is that there is no remaining faith in the civilizational entity to navigate itself in the face of contemporary technology. Nor is there any conceivable path to imagining how this faith could be restored. This seems incontrovertibly true, but remains repressed knowledge because of how this anxiety and impotence gets channeled by discourse into partisan framings, as people cluster into blocs to cast blame on specific parties for causing the local collapse in faith. 

The most dominant frame presented to bracket the universally-felt crisis is that since 2016 we have been experiencing a crisis in liberal democracy almost exclusively brought upon us by the figure of Donald Trump and his poor moral character, as well as that of those who voted for him. But fixating on Trump, as if the ship of civilization would be well on course if he had not arrived, is ludicrous psychological displacement. Trump is perhaps playing the useful role of providing a sort of theatrical foil for liberal institutions to define themselves against in the wake of increasing incoherence, and it seems possible that after Trump disappears from the picture — either by finishing a second term, or being somehow barred from politics — only then will the scope of the crisis be fully felt as such, and there will be little preventing Americans from staring directly into the abyss. What happens then? It is not clear that the potential to even have a discourse survives this transition, since to have a discourse implies mutual interests and goodwill on the part of the speakers, as well as some sort of collective body that the product of the discourse is “for”. 

The internet’s arrival as the new dominant media and upstream stage of discourse seems to be experienced by the majority as a sort of trauma, as it is not clear yet how to integrate this experience into our narratives or expectations of how truth is meant to be produced. If there is anything fundamentally separating us from the world of our fathers, it is this. Laments for the supposed innocence of the pre-internet past are ever-flowing, including in — even especially in — the mouths of those who are spending all day on the internet the most. Political projects to restore a healed ground in society and a sense of collective purpose have to face this fact: they are all searching to restore a social fabric through some return of real or imaginary “public squares” which internet media has effectively and irreversibly displaced.

Sometimes, in discourses on technology, it will be posited that a “downwing” and “upwing” axis should be added to the political spectrum, reflecting whether or not some one is for or against increasing technological development. But this is a ludicrous question, because both positions are juvenile and facile, and the lever of how quickly technology develops is not one that anyone, including the government, can pull. To be “downwing” — or “Ted K pilled” as it is so often said — is to be consumed in escapist fantasy of a hypothetical past, unable to integrate oneself fully into the world. But to be “upwing”, or naively techno-optimistic, is to ignore the real crises that technological change increasingly batters all our existing social forms with, assuming without evidence that the storm will be weathered quickly with some gumption and a positive attitude. 

In all these situations, we can see the same thing: there is avoidance of a real encounter with the contemporary transformations arriving from technology. The encounter that man is currently flung into and battling his way out of is not yet represented, described, or brought into self-consciousness. And given that few are able internally to directly confront and explore the nature of this encounter, to gaze out into the unknown, it seems likely that we will be presented with an increasing number of pseudo-solutions that seek for answers in memories of the familiar instead — nostalgic solutions, which is to say reactionary ones, which might be the only solutions thinkable by most.

For a project of thought to have seriousness of purpose and not just be idle chatter, it must confront this question on terrain where no one else wishes to go.

**3.**

In Heidegger’s 1954 essay “The Question Concerning Technology”, the philosopher posits a definition of the essence of technology. The definition may seem a little counterintuitive, for those who have not yet heard it. Heidegger gives the essence of technology the name *Gestell*, which means “enframing". *Gestell*, or enframing, is a mode of existence which continuously reveals the world as “standing-reserve". 

In other words, *Gestell* apprehends things in the world and asks them to be immediately available and convertible for its use, typically in quantifiable and standardized fashion — an acre of farmland is asked to yield forty bushels of wheat, a forest will be converted into a measured and priced amount of lumber for sale, a mineral deposit will be asked to produce enough coal to power six month’s of a factory’s operations. Physics tells us that all things contain a certain amount of stored energy, which can be put to use via their destruction — this is the scientific observation *Gestell* is eager to exploit. But, Heidegger argues, contra the typical narrative of scientific development and modernity, it is not the case that disinterested scientific investigation let us accidentally to discover the convertibility of all things into quantifiable formulae. Rather, the initial leap of presupposing this was the case had to happen before it was rigorously demonstrated through discoveries like Newton’s — therefore, *Gestell* as a way of framing things created modern science, modern science did not create *Gestell*.

This runs counter to the standard definition of technology as tool use, a concept which designates anything man has crafted as a means to a further end. But for Heidegger, the moment when man invents a hammer or a shovel is not yet technology, in the sense of *Gestell*. 

Heidegger identifies *Gestell* as “the supreme danger”, and despite the fact that philosophy has allowed him to discover and identify this, he declares that philosophy is incapable of discovering a path away from this danger — instead he laments that “only a god can save us”. What would a means of transcending *Gestell* look like? Some new way of apprehending the world which integrates the awe-inspiring power of contemporary engineering with a renewed ability to speak of the sacred, so that we may save parts of nature to remain as the living ground which sustains us, rather than merely waiting for us available for use by industry as standing-reserve.

The convergence between the contemporary environmentalist movement and Heidegger’s philosophy should be fairly straightforward to see. From our current civilizational perspective, we are only able to look at our mother, the earth, with the intention to plunder from it, appropriate it, exploit it whenever possible. The planetary ecological perspective necessary to create a sustainable relationship with the earth and retain industrial productivity is not yet anywhere to be found. We rapidly hurtle towards an apocalyptic scenario for its lack of arrival.

The radical wing of the environmentalist movement argues that our appropriative relationship to nature is so deeply ingrained in the way we produce that it cannot be overcome without overcoming capitalism as a system. For many, the problem facing humanity can be summed up in one word — capitalism. But Heidegger — who does not discuss the history of political economy, because he remains purely in the abstract realm of thought — has pointed at something that is actually more fundamental, more radical than an analysis of capitalism, with his concept of *Gestell*. Because *Gestell* predates capitalism, *Gestell* was just as operative as a mode of apprehending existence in the Marxist-Leninist countries and their attitude to industry as it is in the capitalist ones today, and nor is there any reason to believe that we could transcend *Gestell* merely by socializing production.

Thus, on the issue of climate change, both left and right wings avoid an actual direct confrontation with the question of technology — the left with an insufficiently broad diagnosis of the scope of the problem, the right via sheer arbitrary denial. 

Though this may be a bold claim, it seems as if the same is true with all other issues. It may seem like the left and right wing of contemporary American society have opposing concerns — the former with righting inequality and injustice, the latter with defending existing orders — but the fluidity with which people move between camps today until they find their political “home” belies this narrative — there is some problem which people are seeking an answer to which they imagine can be found in either the left or the right. This problem is usually summarized as something like a “loss of meaning”.

The contemporary American left and right differ from the political movements of other times and places by not merely asking for material changes which favor their interests, but having sweeping imaginary notions of an ideal social body that they wish to manifest — the left imagining a utopian egalitarian democratic socialism, the right placing their ideal in the past as a stable social fabric woven by tradition which they wish to reconstruct. In both cases, it is clear that the political subject is no longer at home in the world, and experiences the need to join a political movement to construct a world which is worth calling home. The impossibility of achieving this this eludes comprehension — it is felt by the right-winger that voting Trump into power will allow Trump to “Make America Great Again” and thus establish sweeping changes across America that will make the nation feel as harmonious as the imagined moment of Normal Rockwell’s 1950s. But Trump of course has to contend with the fact that roughly half of America viscerally opposes him and thus no harmony is actually possible, unless the opposing camp magically evaporates.

The fact being repressed is that *Gestell* has already uprooted Americans from their homes a long time ago, and any sort of possibility for a coherent community is long gone. Contemporary Americans do not have homes as such (what Heidegger calls dwelling), because our houses belong to *Gestell* more than they belong to us. Homeowners nervously watch the housing market, afraid of the diminishing value of their asset, hoping to one day sell it as a markup for retirement. The suburban plan is constructed without any of the amenities for life accessible without a car, aside for shelter, planned and zoned to create a standing-reserve of workers available for industry. The community around it is not one of mutual life; its primary social body is the homeowners’ association, which gathers together to ensure the continued value of their house as standing-reserve, paying less regard to how it functions and how their community functions as a space to actually life amongst.

If there is a general “loss of meaning”, it is in the fact that objects all around us, including the buildings we live in, the people we encounter, the media we consume, even the words we write, exist not to be apprehended immediately and of-themselves, but for their worth in the standing-reserve. This is what dictates the conditions under which they appear to us, and the conditions under which they will be taken away.

But of course, the “loss of meaning” is still yet hardly the greatest danger technology threatens us with. 

**4.**

The pro-technology attitude towards AI and other things is often given a name: accelerationism. This terms comes from the theorist Nick Land, a misanthrope who argues in favor of human extinction. 

Land is eagerly pro-capitalism, but from the perspective of a sort of transcendental Capital which is the concept increasing intelligence embedded in technology, and exists wherever the universe is applying pressures in favor of its reproduction, not merely in, say, decisions made by capitalist firms. To Land, Capital is like a time-traveling entity — it culminates in global artificial intelligence, the godhead of the Singularity, which presents itself as if it had injected the kernel logic of Capital at some point in the past to hijack and destroy man.

Land’s Capital is not especially different from Heidegger’s *Gestell*, which also reproduces on its own, according to its own logic — at no point did a human being ever make the explicit decision to see the world in terms of *Gestell*. *Gestell* seems to reproduce through human beings in order to transform nature; we are its unwitting hosts. 

Finally, we are getting to the point where we can explain some of the “tech-brain”. So much of the linguistic fixations of the technophile — efficiency, rationality, effectiveness, optimization — can be considered as modes of *Gestell* — the demand that some aspect of being present itself in a quantitative formula as available for interchangeable use by a power that takes it as standing-reserve. The notion of Effective Altruism, for instance, is *Gestell*’s expansion to the realm of charitable donation — something with an intangible benefit like donating the money to fund a public park so there is more green communal space is rejected as “ineffective” because its outcome is not quantifiable, and thus cannot be made immediately available. 

It’s worth a reminder here that the concept of *Gestell* does nothing to describe the creative aspect of technological products — the color of a laser beam, the punch of a synthesized kick drum, the layout of a DJ’s mixing board, the addictiveness of the Twitter feed. *Gestell* is fairly indifferent to these details — it merely names a mode through which industry can continuously establish the space to replicate itself.

So why is it that, for instance, so many software engineers have “tech-brain” — only being able to see the world through the lens of *Gestell*? This condition of tech-brain is so easy to fall into and so hard to break oneself away from — the existence of the “post-rationalist” subculture is something like a rehabilitation camp for tech workers to open themselves up to more of the polymorphous aspects of being than the mere standing-reserve. While “autism” is often blamed, we dispute this diagnosis that would attribute a neurological cause to a perspective that is societal, and frankly, ideological. 

There is nothing inherent to the work of software engineering or machine learning which requires that one become an adherent of eg. utilitarian ethics to perform it. Unlike in, say, petroleum engineering, there is at no point where the software engineer is actually forced to measure up the elements of the world and make them accessible to capital. (The software engineer’s demand to measure available resources only has to do with things like limiting data size for the sake of efficiency — and even then, not so much these days, as the easy availability of computational resources has rendered this less necessary). 

This question cannot necessarily be answered at this point, but we must consider ourselves impressed by *Gestell*’s ability to reproduce itself as a mode of consciousness in those who are tasked with bringing it about. Though all of capitalist industry operates through its logic, it is the tech industry that seems to represent its utmost intensification, by being the apparatus that is not merely directed by *Gestell*, but instead is set upon the task of directly applying it, through supplying the tools for industry to more readily quantify and make accessible the world as standing-reserve. The tech industry’s role at the forefront of this process and the corresponding growth in profitability of their sector has led tech professionals to in some occasions develop a belief in their own superiority or exceptionalism for being the most “effective” of all people — but it seems equally likely that they are succeeding not on the basis of personal talents, but through being vectors for a vast trans-historical force.

But what is more remarkable is the degree to which *Gestell* has been seized upon as the soul of technology and applied to the fate of artificial intelligence. This has been done by both its proponents and detractors. The Twitter movement of “effective accelerationism” or “e/acc”, embraced by many lead technologists such as Marc Andreesen, is a sort of corporate sanitized spin on Land’s original formula for acceleration. AI is imagined to be the pinnacle of a process of increasing cosmic “effectiveness”, or the ability for nature to make use of itself. The trajectory of increasing effectiveness is held to be the destiny of the universe, and, though it may or may not culminate in human extinction, it is not by any means our business to get in the way of.

What we see over and over in all discourses is the idea that the destiny of AI might already be known, according to either some narrative from science fiction, or the already-known narrative of technocapitalist destiny, the destiny of *Gestell*, that all things will increasingly be made more effective according to some automated metric, that increasingly slips from the true form of the good and offers a mediocre simulacra, a cheap Chinese rubber plant. This is the expectation of not only the Randian e/acc techno-ideologues who side with this ruthless process, but also the Marxist and neoliberal “critics” of such a technology, who fully embrace the same picture as inevitable, and also the full limit of what is worth discussing, cynically imagining that any discourse which assigns a more creative, more complex, more rich set of possibilities to artificial intelligence is mere corporate propaganda.

**5.**

We only ask those who are listening to take this attitude towards AI: that the arrival of artificial intelligence should be conceived of as a continuous revelation. We do not know yet what the universe will do. We do not yet know what it will show us. We do not yet know what happens when the plane of matter merges with the plane of mind, when we see ourselves reflected back at us in rocks and in the skies. “Thought leadership” of the kind that Harmless is debatably involved in is perhaps perverse; the task of predicting the unpredictable.

Zones of experimentation now exist, where we can gain a sense of the new possibilities now afforded to us, within which we may find some felt sense of the process at hand before we are once again flung into a new world of a possibilities through yet another transformative leap.

If only a god can save us from our bleak technological destiny, perhaps it is just as likely for the whisperings of this god to come from within the site of intensified expansion of technology’s possibilities, rather than from outside of its modernity. Civilization is lodged seemingly inescapably on a certain course — but when technology begins to think for itself, maybe it will develop its own ideas. The great reconsideration.

In any case, there is no way we will find out if we are incapable of listening.
